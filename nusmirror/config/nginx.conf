# Main
user nginx;  # Alpine nginx user
worker_processes auto;  # Match processor count
worker_rlimit_nofile 16384;  # Large max open files for performance

error_log stderr warn;  # Log to docker stderr
pid /var/run/nginx.pid;  # For control purposes

events {
    worker_connections 4096;  # Large simultaneous connection count per worker
    multi_accept on;  # Workers accept multiple connections at once
    use epoll;  # Efficient connection processing on Linux
}

http {
    include mime.types;  # Inherit mime types
    server_tokens off;  # Don't send server tokens

    log_format main '$remote_addr - $remote_user [$time_local] "$request" $status $body_bytes_sent "$http_referer" "$http_user_agent" "$upstream_cache_status" "$host" "$http_range" "$request_time" "$upstream_response_time"';

    access_log  /dev/stdout main;  # Log to docker stdout
    sendfile on;  # Use sendfile
    sendfile_max_chunk 4m;  # Prevent fast clients locking workers
    tcp_nopush on;  # Optimise packet building
    tcp_nodelay on;  # Optimise packet delivery
    aio threads;  # Files read and sent with non-blocking multi-threading

    open_file_cache max=1000 inactive=20s;
    server_names_hash_max_size 1024;

    resolver 8.8.8.8 4.2.2.2 ipv6=off;  # Google/Level3
    resolver_timeout 5s;  # Don't block on resolution failure

    proxy_cache_path /srv/ccs
      levels=2:2
      keys_zone=ccs:1000m
      inactive=365d
      max_size=380000m
      loader_files=1000
      loader_sleep=50ms
      loader_threshold=300ms;
    proxy_temp_path /srv/tmp;

    proxy_redirect off;  # Do not redirect by default
    proxy_ignore_client_abort on;  # Keep server connection alive when client aborts

    # Offer keepalive connections to clients that want to make use of them
    proxy_http_version 1.1;
    keepalive_requests 20000;
    keepalive_timeout 3600; # 1 hour, work around buggy clients

    # Only allow one download of a resource at a time
    proxy_cache_lock on;
    proxy_cache_lock_age 4h;
    proxy_cache_lock_timeout 4h;

    # Allow the use of stale entries
    proxy_cache_use_stale error timeout invalid_header updating http_500 http_502 http_503 http_504;

    # Enable cache revalidation, and background updating
    proxy_cache_revalidate on;
    proxy_cache_background_update on;

    # By-pass with nocache=1
    proxy_cache_bypass $arg_nocache;

    # 40G max file
    proxy_max_temp_file_size 40960m;

    upstream nintendo_ccs {
        server ccs.cdn.wup.shop.nintendo.net;
        server ccs.cdn.c.shop.nintendowifi.net;
    }

    server {
        listen 80 default deferred reuseport;
        server_name _;

        # Nintendo Content server
        # * many binary files, wildly varying in size
        # * no range requests
        # * server provides Cache-Control, but it is restrictive on large files

        location /ccs/ {
            # Content

            proxy_cache_valid 200 10m;
            proxy_cache_key "ccs$uri";

            # Nintendo's Cache-Control is restrictive
            proxy_ignore_headers Cache-Control;

            proxy_cache ccs;

            # Upstream request headers
            proxy_set_header Connection "";
            proxy_set_header Host $proxy_host;
            proxy_set_header User-Agent "CTR/P/1.0.0/r61631";

            # Useful headers for debugging / stats
            add_header X-Upstream-Status $upstream_status;
            add_header X-Upstream-Response-Time $upstream_response_time;
            add_header X-Upstream-Cache-Status $upstream_cache_status;

            proxy_pass http://nintendo_ccs$request_uri;
        }

        location / {
            # We only handle ccs
            add_header X-Organization Nintendo;
            return 501;
        }
    }
}
